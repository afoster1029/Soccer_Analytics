---
title: "Predicting MLS Matches using Machine Learning Techniques"
author: "Alex Foster, Chris Bajek, Webster An"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
abstract: "Predicting the outcome or different statistics of sports is a massive market for betting and gambling. Additionally, in crisis such as a global pandemic, predicting results can be crucial for determining how the season would have ended. For this project, we will use different machine learning techniques that we learned in Statistical Machine Learning to determine how to predict the outcome of matches in the Major Soccer League. Using data on the MLS season from 2012-2018 we hope to make some predictions regarding the 2019 season"

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load packages
library(ggplot2)
library(dplyr)
library(janitor)
library(reshape2)
library(tidyr)
library(readr)
library(lubridate)
library(Matrix)
library(DataCombine)
library(rsample)
library(caret)
library(broom)

#plotting and exploring
library(tidyverse) #for plotting and summarizing
library(GGally) #for nice scatterplot matrix 
library(ggridges) #for joy/ridge plots
library(corrplot) #for basic correlation matrix plot
library(naniar) #for exploring missing values
library(pdp) #for partial dependence plots, MARS models

#making things look nice
library(knitr) #for nice tables
library(scales) #for nice labels on graphs
library(gridExtra) #for arranging plots
library(broom) #for nice model output

#data
library(ISLR) #for data
library(moderndive) #for data

#modeling
library(rsample) #for splitting data
library(recipes) #for keeping track of any transformations we do
library(caret) #for modeling
library(leaps) #for variable selection
library(glmnet) #for LASSO
library(earth) #for MARS models
library(vip) #NEW for importance plots
library(rpart.plot)

```

## Introduction

Due to the COVID-19 pandemic in 2020, the majority of sports leagues across the world have halted their seasons. This has lead to varying decisions on how to proceed. Since soccer does not have playoffs, the final standings of the league dictate which teams are promoted or relegated. This can have a massive financial effect on teams in relegation and promotion positions. Some leagues have decided to cancel the rest of the remaining season, while other leagues, like France's Ligue 1, have decided to end the league as it stands, crowning the current 1st place team. This decision has resulted in several lawsuits. 

In the USA, Major League Soccer does not implement promotion or relegation and uses the playoff system like many other American sports leagues. However, due to the chaos in European soccer leagues, we wanted to see if we could create a model that could predict the number of goals each team will score in an MLS match. We intend to do this by examing each team's overall statistics for each game and team's season statistics as well. We recognize that this a very difficult task and that soccer, in particular, is one of the hardest sport's to model not only because of the lack of data but also due to the nature of the sport. 


## The Dataset 

```{R,echo=FALSE, message=FALSE}
MLS <- read_csv("USA.csv")

# create datetime objects using lubridate. 
# also initialize variables for each game that will measure home/awayteam goals per game and home/away team goals conceded per game
MLS <- MLS %>%
  mutate(HAGG = 0.0, AAGG = 0.0, HACG = 0.0, AACG = 0.0, HTP=0, ATP = 0,TG = HG + AG, Datetime = dmy(Date),  month = month(Datetime)) %>%
  select(Country, League, Season, Datetime, Home, Away, HG, AG, Res, HAGG, AAGG, AACG, HACG,HTP,ATP,TG, PH, PD, PA)

```

The dataset that we used provides brief overall match statistics of all MLS matches from 2012-2020. The dataset was provided by http://www.football-data.co.uk/usa.php, which is used primarily to compute betting odds. As a result, our dataset contains not only the relevant match information but also the betting odds for each potential result. Since 2012 there have been 2794 matches. The graph below represents the number of matches for each season. The increase of matches in each year is due to the constant expansion in MLS. This means that in each new season there are brand new teams with no previous match data. We anticipate this having a negative effect on the performance of our models. 

```{r,echo=FALSE,fig.align='center'}
ggplot(MLS, aes(Season)) + geom_bar() + ylab("Total Games") + ggtitle("MLS Dataset")
```

The initial dataset provided us with the outcome and date of each match, teams playing, the number of goals scored by each team and the betting odds. We recognized that we would need more explanatory variables. We created a function that would compute the league table prior to a given date. This allowed us to compute each team's average goals scored per game, average goals conceded per game for each match, and their position in the league. However, even with our additional explanatory variables, we wrangled our dataset to be better designed for predictive modeling. We split each match into two rows. This meant that each row represented a team with that team's relevant information. Ultimately, our plan is to have our response variable be Goals. Our dataset had the  following structure. 

\newline

<table style="border:2px solid black;margin-left:auto;margin-right:auto;">
<tr> <th>  </th> <th> Variable Name </th> <th> Description </th>  </tr>
  <tr> <td align="center"> 3 </td> <td align="center"> Season </td> <td align="center"> Calendar year that a given season occurred (2012 - 2020) </td> </tr>
  <tr> <td align="center"> 4 </td> <td align="center"> Datetime </td> <td align="center"> Represents the date the match was played on (lubridate datetime object) </td> </tr>
  <tr> <td align="center"> 5 </td> <td align="center"> Team </td> <td align="center"> Team that we will predict number of goals for. </td> </tr>
  <tr> <td align="center"> 6 </td> <td align="center"> Opponent </td> <td align="center"> Team's opponent for given match </td> </tr>
  <tr> <td align="center"> 7 </td> <td align="center"> Goals </td> <td align="center"> Team's goals scored in the given match </td> </tr>
  <tr> <td align="center"> 8 </td> <td align="center"> GoalsAllowed </td> <td align="center"> Opponent goals scored in the given match </td> </tr>
  <tr> <td align="center"> 9 </td> <td align="center"> Res </td> <td align="center"> Final result of the match (H/A/T) </td> </tr>
  <tr> <td align="center"> 10 </td> <td align="center"> AGS </td> <td align="center"> Team's average goals per game prior to this match </td> </tr>
  <tr> <td align="right"> 11 </td> <td align="center"> OpAGC </td> <td align="center"> Oppoent's average goals conceded per game prior to this match </td> </tr>
  <tr> <td align="right"> 12 </td> <td align="center"> Position </td> <td align="center">  Team's league position prior to this match </td> </tr>
  <tr> <td align="right"> 13 </td> <td align="center"> OpPosition </td> <td align="center"> Oppoent's league position prior to this match </td> </tr>
  <tr> <td align="right"> 14 </td> <td align="center"> TG </td> <td align="center"> Total goals scored in this match </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> TableDiff </td> <td align="center"> Team's difference in table position with opponent </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> GoalDiff </td> <td align="center"> Team's goal differential prior to this match </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> GoalScCo </td> <td align="center"> The sum of AGS and OpAGC variables </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> HA </td> <td align="center"> Dictates whether the Team is home or away for the given match </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> PH </td> <td align="center"> Betting odds of a home win </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> PD </td> <td align="center"> Betting odds of a draw </td> </tr>
  <tr> <td align="right"> 15 </td> <td align="center"> PA </td> <td align="center"> Betting odds of an away win </td> </tr>
   </table>
   
   
\newline 

```{r, echo=FALSE, cache=TRUE}
# Function that computes the table of the season given a certain date in the season.
# Returns a dataframe that provides stats dependent on the progress of the given season 
compute_table <- function(date, df=USA) {
    # Get only the games that are in the same season and occured before the given date. 
    season = year(date)
    df_subset <- df[which(df$Season == season & df$Datetime < date), ] # get games from that season and up to the given data
    # get team names
    names <- unique(df[which(df$Season==season),]$Home)
    # initialize beginning of season table (stats are all zero)
    table <- data.frame("Team" = names, "Points" = matrix(0,length(names)), "GA" = matrix(0,length(names)), "GF" = matrix(0,length(names)), 'GP' = matrix(0,length(names)))
    if (nrow(df_subset) != 0){
        # Loop through each game and update the explanatory varaibles such as GA, GF, GP. All of these values are dependent on the date of the game. 
        for (row in 1:nrow(df_subset)) {
            current_r =df_subset[row, ]
            # Update info for home team
            home <- current_r$Home
            table$GA[which(table$Team == home)] <- table$GA[which(table$Team == home)] + current_r$AG# GA
            table$GF[which(table$Team == home)] <- table$GF[which(table$Team == home)]+current_r$HG# GF
            table$GP[which(table$Team == home)] <- table$GP[which(table$Team == home)]+1
            
            # Update info for away team
            away <- current_r$Away
            table$GA[which(table$Team == away)] <- table$GA[which(table$Team == away)]+current_r$HG# GA
            table$GF[which(table$Team == away)] <- table$GF[which(table$Team == away)]+current_r$AG# GF
            table$GP[which(table$Team == away)] <- table$GP[which(table$Team == away)]+1
            
            # Award points to winner and for ties. 
            if (current_r$Res == 'H'){ # home wins
              table$Points[which(table$Team == home)] <- table$Points[which(table$Team == home)] + 3
            } else if (current_r$Res == 'A'){ # away wins
              table$Points[which(table$Team == away)] <- table$Points[which(table$Team == away)] + 3
            } else { # draw
              table$Points[which(table$Team == home)] <- table$Points[which(table$Team == home)] + 1
              table$Points[which(table$Team == away)] <- table$Points[which(table$Team == away)] + 1
            }
        }
        # compute goal differential
        table <- table %>%
          mutate('GD' = GF - GA)
        # add AGSG column that represents the avg goals scored per game
        table <- table %>%
          mutate(AGSG = GF / GP)
        # add AGCG column that represents the avg goals conceded per game
        table <- table %>%
          mutate(AGCG = GA / GP)
        # Add position column that indicates what place each team is in. 
        table <- table[with(table,order(table$Points, table$GD)),]
        table$Position <- length(names):1
    }
  return(table)
}
```

```{r, echo=FALSE, cache=TRUE}
# Function computes table for every game and updates the current season stats like Avg goals scored, avg goals conceded and position in the league. 
add_table_stats <- function(df = usa_2012) {
    for (row in 1:nrow(df)){
      game = df[row,]
      # compute table 
      table <- compute_table(game$Datetime, df)
        # add home/away team average stats based on season performance up to that game.
        if (table[1,]$GP != 1){ # if games played is 1 then we don't really want average stats (avoids potential errors)
            if(game$Home %in% table$Team & game$Away %in% table$Team){ # check that both teams are actually in table.
                # home team stats
                df[row,]$HAGG <- table$AGSG[which(table$Team == game$Home)]
                df[row,]$HACG <- table$AGCG[which(table$Team == game$Home)]
                df[row,]$HTP <- table$Position[which(table$Team == game$Home)]
                # away teams stats
                df[row,]$AAGG <- table$AGSG[which(table$Team == game$Away)]
                df[row,]$AACG <- table$AGCG[which(table$Team == game$Away)]
                df[row,]$ATP <- table$Position[which(table$Team == game$Away)]
            }
        }
    }
    return(df)
}
```
 
```{r,echo=FALSE, cache=TRUE}
# initialize final dataframe with 2012 season
USA_final <- add_table_stats(MLS[which(MLS$Season==2012),])
# loop through all other seasons that aren't 2012 and compute season statistics.
for (season in unique(MLS$Season)){
  if (season != 2012){
    updated_df <- add_table_stats(MLS[which(MLS$Season==season),])
    USA_final <- rbind(USA_final, updated_df)
  }
}

write.csv(USA_final,"USA_final.csv", row.names = TRUE)
```

```{r,echo=FALSE,message=FALSE,warning = FALSE, cache=TRUE}
# Read in dataset (avoid long code run)
MLS_df <- read_csv("USA_final.csv",)
MLS_df <- MLS_df[which(MLS_df$PH != 'USA'),]
MLS_df <- subset(MLS_df,select= -c(X1))
```

```{r, echo=FALSE, cache=TRUE}
Home <- MLS_df
Home$Country <- NULL
Home$League <- NULL
Home$Date <- NULL
Home$Time <- NULL
# Home$Away <- NULL
Home$AAGG <- NULL
Home$HACG <- NULL
Home <- Home %>% 
  rename(
    Team = Home,
    Opponent = Away,
    Goals = HG,
    GoalsAllowed = AG,
    Position = HTP,
    AGS = HAGG,
    OpAGC = AACG,
    OpPosition = ATP
    )
Home <- cbind(Home, HA = "H")
Away <- MLS_df
Away$Country <- NULL
Away$League <- NULL
Away$Date <- NULL
Away$Time <- NULL
# Away$Home <- NULL
Away$HAGG <- NULL
Away$AACG <- NULL
Away <- Away %>% 
  rename(
    Team = Away,
    Opponent = Home,
    Goals = AG,
    GoalsAllowed = HG,
    Position = ATP,
    AGS = AAGG,
    OpAGC = HACG,
    OpPosition = HTP,
    Opponent = Home
    )
Away <- cbind(Away, HA = "A")
MLS_final <- rbind(Home, Away)

MLS_final[,"Position"] <- sapply(MLS_final[, "Position"], as.numeric)
MLS_final[,"OpPosition"] <- sapply(MLS_final[, "OpPosition"], as.numeric)
MLS_final[,"AGS"] <- sapply(MLS_final[, "AGS"], as.numeric)
MLS_final[,"OpAGC"] <- sapply(MLS_final[, "OpAGC"], as.numeric)
MLS_final <- MLS_final %>%
  mutate(TableDiff = Position - OpPosition,
         GoalDiff = Goals - GoalsAllowed,
         GoalScCo = AGS + OpAGC)
if ('X1' %in% names(MLS_final)){
  MLS_df[ , !(names(MLS_df) %in% c('X1'))]

}

# Accounting for the fact that Atlanta United has two different names "Atlanta United" and "Atlanta Utd"

# Create replacements data frame
Replaces <- data.frame(from = "Atlanta Utd", to = "Atlanta United")

# Replace patterns and return full data frame
MLS_final1 <- FindReplace(data = MLS_final, Var = "Team", replaceData = Replaces,
                     from = "from", to = "to", exact = FALSE)
MLS_final <- MLS_final1
remove(MLS_final1)
MLS_final <- MLS_final %>% 
  mutate(`PH` = as.numeric(`PH`)) %>% 
  mutate(`PD` = as.numeric(`PD`)) %>% 
  mutate(`PA`= as.numeric(`PA`))
#head(MLS_final)
```

### Data Visualizations

```{r,echo=FALSE,fig.align='center'}
# Distrbution of goals by season (broken into months)
MLS_final %>% 
  ggplot(aes(x = Goals)) +
  geom_bar(colour = "#0c4c8a") +
  facet_wrap(~Season)+
  theme_minimal() +
  ggtitle("Goals by Season (Broken in to Months)") +
  theme(plot.title = element_text(hjust = 0.5))
```

\newline

*The visualization above shows the total number of goals scored by all teams over the months in which a season is played for each season in the data set. One can observe that the first few months have the highest amount of total goals because these are the months in which there is the highest concentration of games.* 


```{r,echo=FALSE,fig.align='center',warning=FALSE}
# Distribution of full time results  by season
MLS_final %>%
  ggplot(aes(x = Res)) +
  geom_bar() +
  scale_fill_hue() +
  facet_wrap(~Season)+
  theme_minimal() +
  ggtitle("Full Time Results by Season") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

*The graph above depicts full-time results as an Away Win (A), Draw (D), or Home Win (H). As we expect the most common result is a home win, seeming to prove that there is such a thing as home-field advantage.* 
\newline

```{r,echo=FALSE,fig.align='center',message=FALSE,warning=FALSE}
# Total Goals by team
MLS_final %>%
  ggplot(aes(x = Team, y = Goals)) +
  geom_col() +
  scale_fill_hue() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  ggtitle("Total Goals by Team") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

*This plot shows the total number of goals scored by individual teams in MLS. The Total number of goals can be misleading though because some of the teams are much newer than others and haven't had an opportunity to score goals in all of the seasons in our data.* 
\newline


```{r,echo=FALSE,fig.align='center',message=FALSE,warning=FALSE}
# Examining average goals scored
MLS_final %>%
  group_by(Team) %>% 
  mutate(avg_goals=AGS/n()) %>% 
  ggplot(aes(x = Team, y = avg_goals)) +
  geom_col() +
  scale_fill_hue() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  ylab("Average Goals per Game") +
  ggtitle("Average Goals by Team") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

*This plot is similar to the previous one except that it examines the average goals scored per game by each team. The Miami team and the Nashville team were just added to the league so it makes sense that they have little to no goal information.* 

\newline

```{r,echo=FALSE,fig.align='center',warning=FALSE}
# Examining relationship between AGS and Position by team
MLS_final %>% 
  ggplot(aes(x=AGS, y=Position)) +
  geom_point(alpha=.5) +
  scale_fill_hue() +
  facet_wrap(~Team)+
  theme_minimal() +
  ggtitle("Average Goals by Table Position") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

*The plots above show how the average number of goals relates to a team's position in the MLS table. The lower the position on the y-axis the better a team is doing (being 4th in the table is better than 24th). Generally, it looks like the trend is that a higher number of average goals means a better position in the table.* 

\newline

```{r,echo=FALSE,fig.align='center',warning=FALSE}
# Number of goals scored by team during home games or away games
MLS_final %>% 
  ggplot(aes(x=HA, y=Goals)) +
  geom_col() +
  scale_fill_hue() +
  facet_wrap(~Team)+
  theme_minimal() +
  ggtitle("Total Goals Scored at Home and Away") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

*The plot above shows the number of home and away goals each team has scored over the seasons our data includes. As the results graph show previously, we expect there to be a home-field advantage and this plot shows there is.* 


## Modeling: Predict Goals Variable

#### Create training/testing set

```{r, cache=TRUE,include=TRUE}
df_modeling <- MLS_final
df_train <- df_modeling[which(df_modeling$Season != 2019),]
df_train <- df_modeling[which(df_train$Season != 2020),] # remove 2020 from training set.
df_test <- df_modeling[which(df_modeling$Season == 2019),]

```

Our training set includes all matches from 2012-2018 which is represented by 5006 rows. Our test set contains all matches in the 2019 season and contains 828 rows. 

\newline
\newline

#### Stepwise Selection of Variables
```{r, cache=TRUE,echo=FALSE, warning=FALSE}
set.seed(123) 
split <- trainControl(method = "cv", number = 5)

cv_MLS_all_vars <- train(
  Goals ~ .,
  data = df_train %>% select(-Datetime, -Season, -Res, -TG),
  method = "leapForward", 
  tuneGrid = data.frame(nvmax = 1:61), 
  trControl = split,
  na.action = na.omit
)

# cv_MLS_all_vars$results
# cv_MLS_all_vars$bestTune
tidy(coef(cv_MLS_all_vars$finalModel,id=60))
```

```{r,,echo=FALSE, message=FALSE,warning=FALSE,fig.align='center'}
cv_MLS_all_vars$results %>% 
  ggplot() +
  geom_line(aes(x=nvmax,y=RMSE),color="blue") +
  geom_line(aes(x=nvmax,y=RMSE + RMSESD)) +
  geom_line(aes(x=nvmax,y=RMSE - RMSESD))+
  theme_minimal() +
  ggtitle("Stepwise Selection RMSE vs NVMax") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

Using the stepwise selection method to examine which variables are most relevant for our model we can see that the best tune is 60 explanatory variables. The coefficients and the variables are shown in the tidy table above. It's important to note that there are 50 variations of the team and opponent categorical variables because there are 26 teams total. The intercept is the Atlanta United team.

\newline
\newline

#### OLS
```{r, cache=TRUE,echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123) 
split <- trainControl(method = "cv", number = 5)

ols_model <- train(
  Goals ~ Team + Opponent + GoalsAllowed,
  data = df_train,
  method = "lm", 
  trControl = split,
  na.action = na.omit
)
tidy(summary(ols_model))
# (ols_model$results)
```
Using the stepwise selection as a guide we have chosen to run an OLS model with Team, Opponent, and GoalsAllowed as the explanatory variables for Goals. Our model summary shows the coefficients and the RMSE is 1.213 when using the training data.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123) 
split <- trainControl(method = "cv", number = 5)

ols_model_test <- train(
  Goals ~ Team + Opponent + GoalsAllowed,
  data = df_test,
  method = "lm", 
  trControl = split,
  na.action = na.omit
)
# summary(ols_model_test)
ols_model_test$results
```
When using our OLS model on the testing data we have a CV RMSE of 1.3 which is slightly higher than the training CV RMSE.

\newline
\newline

#### Lasso Model 
```{r,echo=FALSE, message=FALSE, warning=FALSE}

model_stats <- function(data, lev = NULL, model = NULL) {
  
  stats <- defaultSummary(data, lev = lev, model = model)
  
  transf_rmse <- function (pred, obs) {
    sqrt(mean((exp(obs) - exp(pred))^2))
  }
  
  trmse <- transf_rmse(pred = data$pred,
                       obs = data$obs)
  c(tRMSE = trmse, stats)
}

lambda_grid <- 10^seq(-4, -1 , length = 50)
#Credit for Model_stats code goes to Lisa Lendway. 

```

```{r,echo=FALSE, message=FALSE, warning=FALSE}
set.seed(327)
MLS_lasso <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo,
  data = df_train, 
  method = "glmnet",
  tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all",
                           selectionFunction = "best"),
  na.action = na.omit,
  metric = "RMSE", 
  maximize = FALSE
)

```


```{r,echo=TRUE, message=FALSE, warning=FALSE,results=FALSE}

set.seed(327)
MLS_lasso_small <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo,
  data = df_train, 
  method = "glmnet",
  tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all",
                           selectionFunction = "oneSE"),
  na.action = na.omit,
  metric = "RMSE", 
  maximize = FALSE
)
```

```{r,echo=FALSE,warning=FALSE}
#MLS_lasso_small$results
#MLS_lasso_small$bestTune
#MLS_lasso_small$results$RMSE[47]
best_lambda_small <- MLS_lasso_small$bestTune$lambda
tidy(coefficients(MLS_lasso_small$finalModel, s = best_lambda_small))

```

```{r,echo=FALSE, message=FALSE, warning=FALSE}
set.seed(327)
MLS_lasso_small_test <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo,
  data = df_test, 
  method = "glmnet",
  tuneGrid = data.frame(alpha = 1, lambda = lambda_grid),
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all",
                           selectionFunction = "oneSE"),
  na.action = na.omit,
  metric = "tRMSE", 
  maximize = FALSE
)
```
\newline

We chose to run two lasso models, one normal lasso model, and one tuned to be the smallest model (the model with the largest lambda within one standard error of the best models). Our first model produced an RMSE of 1.174427 and the smaller lasso model had an RMSE of 1.183064. Both of these values are better than the OLS model and higher than the Stepwise-Selection RMSE. We used the testing set on both these and found that we got an RMSE of 1.2379 for both. This is greater than the training set model RMSE than we would like.

When we examine the coefficients of the smallest model, only 4 terms remain, the largest coefficient being for GoalScCo = 0.029404969.

\newline
\newline
#### MARS MLS Model

```{r,echo=FALSE, message=FALSE, warning=FALSE}
set.seed(327)

MLS_mars <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo,
  data = df_train, 
  method = "earth",
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all"),
                           na.action = na.exclude,
                          
  tuneGrid = data.frame(degree = 1, nprune = 2:8)
)
```

```{r,echo=TRUE, message=FALSE, warning=FALSE}
MLS_mars_best <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo,
  data = df_train, 
  method = "earth",
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all",
                           selectionFunction = "best"),
                           na.action = na.exclude,
  tuneGrid = data.frame(degree = 1, nprune = 2:8)
)
```

```{r,echo=FALSE, message=FALSE, warning=FALSE}

partial(MLS_mars, pred.var = "GoalScCo", grid.resolution = 50) %>%
  autoplot()+
  theme_minimal() +
  ggtitle("Partial Dependence Plot of GoalScCo Variable") +
  theme(plot.title = element_text(hjust = 0.5))

# partial(MLS_mars, pred.var = "HA", grid.resolution = 50) %>%
#   autoplot() 
```
\newline

The output of our Mars models yielded similar results to our previous models. The lowest RMSE of our models occurred for both of them at the 4th prune, corresponding to an RMSE of 1.178. The partial dependence plot of GoalScCo indicates a linear relationship between Goals and this variable which is the sum of AGS and OpAGC. 

\newline
\newline

#### KNN Model

```{r,echo=FALSE, message=FALSE,cache=TRUE, warning=FALSE}
set.seed(327)
MLS_knn <- train(
  Goals ~ Team + AGS + Position + OpPosition + HA + TableDiff + OpAGC + GoalScCo, 
  data = df_train, 
  method = "knn", 
  trControl = trainControl(method = "cv",
                           number = 5,
                           summaryFunction = model_stats,
                           returnResamp = "all"),
  na.action = na.exclude,
  tuneGrid = data.frame(k = c(1:30)))
  

```

```{r,echo=FALSE, message=FALSE, warning=FALSE}
# MLS_knn$results
# MLS_knn$bestTune$k

MLS_knn$results %>%
  mutate(RMSESE = RMSESD/sqrt(5)) %>%
  select(k,RMSE,RMSESE) %>%
  ggplot(aes(x=k, y=RMSE)) +
  geom_point() +
  geom_pointrange(aes(ymin=RMSE+RMSESE, ymax=RMSE-RMSESE)) +
  geom_line(aes(x=k, y=RMSE), color = "#0c4c8a") +
  geom_hline(yintercept = 1.235700 + 0.02363899, color = "black")+
  theme_minimal() +
  ggtitle("KNN RMSE vs K Value") +
  theme(plot.title = element_text(hjust = 0.5))
```
\newline

When we run a KNN model the lowest RMSE, 1.2357, can be observed when k = 15. If we take a look at the best tune parameter, this confirms that k = 15. This model is slightly higher RMSE value than the other models we have tested so far. However, there could be an argument for a model in which k = 10, as this is the simplest model within one RMSE standard error of k = 15.


## Conclusion

Overall, we found that it is very difficult to predict the outcome of games. We expected this to be the case. Additionally, we recognized prior to this project that our explanatory variables in our dataset, even after manipulations, were not that strong. Considering all of this we still found a final model. It is the lasso model that we created. Our two lasso models were created using different selection functions. We found that the first one had a lower RMSE value for the training set but that they both had the same RMSE for the testing set. This led us to go with our smaller lasso model because it was a simpler model.

Additionally, we recognize that this model did not perform very well. We have also considered many future steps for this project. We would first like to start by adding more variables. There are several datasets that have ratings for every player and incorporating this would allow our models to not only compare overall team stats but individual player stats as well. Additionally, we would like to use these predictions of total goals scored by each team to compute the full-time result. By doing this we could call our predictions, compute the final result, and then simulate the rest of the season. We could then store our predictions and the final result and use them to rebuild our model for the next week of games. Unfortunately, these future steps were out the scope of time and resources we had for this project.









